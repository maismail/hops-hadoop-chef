#!/bin/bash

trap "" HUP

#if [ $EUID -eq 0 ]; then
#   echo "this script must not be run as root. su to hdfs user to run"
#   exit 1
#fi

source <%=node['hops']['conf_dir']%>/hadoop-env.sh 

export PATH=<%=node['hops']['bin_dir']%>:$PATH

DFSIO_JAR=<%= @dfsio_jar%>
FILES=20
FILESIZE=1GB

DATE=`date +%Y-%m-%d-%H-%M-%S`
LOGDIR=logs/dfsio/$SIZE/$DATE

if [ ! -d "$LOGDIR" ]
then
    mkdir -p ./$LOGDIR
fi



DFSIO_WRITE_OUTPUT_FILE="./$LOGDIR/dfsio_write_results.txt"

DFSIO_READ_OUTPUT_FILE="./$LOGDIR/dfsio_read_results.txt"


DFSIO_WRITE_LOG_OUTPUT_FILE="./$LOGDIR/dfsio_write_log.txt"

DFSIO_READ_READ_OUTPUT_FILE="./$LOGDIR/dfsio_read_log.txt"


echo Running DFSIO CLEAN job
echo ===============================================================
yarn jar $DFSIO_JAR org.apache.hadoop.fs.dfsioe.TestDFSIO \
-Dmapreduce.map.cpu.vcores=1 \
-Dmapreduce.map.java.opts=-Xmx1229m \
-Dmapreduce.map.memory.mb=1536 \
-Dmapreduce.reduce.cpu.vcores=1 \
-Dmapreduce.reduce.memory.mb=3072 \
-Dmapreduce.reduce.java.opts=-Xmx2458m \
-Dmapreduce.task.io.sort.mb=200 \
-Dmapreduce.task.io.sort.factor=48 \
-Dmapreduce.map.output.compress=true \
-Dmapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.Lz4Codec \
-clean

./run_nmon.sh

echo Running DFSIO WRITE job
echo ===============================================================
{ yarn jar $DFSIO_JAR org.apache.hadoop.fs.dfsioe.TestDFSIO \
-Dmapreduce.map.cpu.vcores=1 \
-Dmapreduce.map.java.opts=-Xmx1229m \
-Dmapreduce.map.memory.mb=1536 \
-Dmapreduce.reduce.cpu.vcores=1 \
-Dmapreduce.reduce.memory.mb=3072 \
-Dmapreduce.reduce.java.opts=-Xmx2458m \
-Dmapreduce.task.io.sort.mb=200 \
-Dmapreduce.task.io.sort.factor=48 \
-Dmapreduce.map.output.compress=true \
-Dmapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.Lz4Codec \
-write -nrFiles $FILES \
-fileSize $FILESIZE \
-resFile $DFSIO_WRITE_OUTPUT_FILE ; } > ${DFSIO_WRITE_LOG_OUTPUT_FILE} 2>&1

NMON_DIR=./$LOGDIR/nmon-write
mkdir -p $NMON_DIR

./stop_and_collect_nmon.sh ${NMON_DIR}

./run_nmon.sh

echo Running DFSIO READ job
echo ===============================================================
{ yarn jar $DFSIO_JAR org.apache.hadoop.fs.dfsioe.TestDFSIO \
-Dmapreduce.map.cpu.vcores=1 \
-Dmapreduce.map.java.opts=-Xmx1229m \
-Dmapreduce.map.memory.mb=1536 \
-Dmapreduce.reduce.cpu.vcores=1 \
-Dmapreduce.reduce.memory.mb=3072 \
-Dmapreduce.reduce.java.opts=-Xmx2458m \
-Dmapreduce.task.io.sort.mb=200 \
-Dmapreduce.task.io.sort.factor=48 \
-Dmapreduce.map.output.compress=true \
-Dmapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.Lz4Codec \
-read -nrFiles $FILES \
-fileSize $FILESIZE \
-resFile $DFSIO_READ_OUTPUT_FILE ; } > ${DFSIO_READ_LOG_OUTPUT_FILE} 2>&1

NMON_DIR=./$LOGDIR/nmon-read
mkdir -p $NMON_DIR

./stop_and_collect_nmon.sh ${NMON_DIR}